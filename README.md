## 1.Talking Head 任务数据集需求
### 1.1内容需求

- **任务核心：音频与对应视频帧需要同步**
- 直接对着相机说话的**单说话人**视频
- **参数信息**
   - **分辨率信息：4K**
   - **编码信息： mp4等编码格式(cv2可以直接处理的编码格式)**
- **语种**
   - **主要目标是亚洲人**
   - **主要语言普通话(mandarin)最好**
- 背景没有需求
- **Take special notice !!!** 
   - 背景音：当说话人正在说话或者停止说话时一直有背景噪声，这种数据不能要
   - 说话人要求：在一个场景中只能有一个说话人存在，多人说话场景是无效的
## 2.说话人处理流程（正在做或者改进的）
### 2.1 处理模块分类

- 可以将整个流程分为
   - 预处理模块
   - 任务处理模块
   - 后处理模块
#### 2.1.1 预处理（数据收集工作）

- 目标
   - 总的来说：主要得到纯说话人的视频片段
   - 视频需要符合下面条件：
      - **不含无人脸场景片段**
      - **不含多人脸场景片段**
      - **不含人在说话或者静默时背景的噪声（声音降噪）**
- 方法
   - 目前采用方法：
      - 第一阶段：扫描视频，按10帧读取一次的方式，记录每次没有人脸以及多人脸的index
      - 第二阶段：根据index区间，起始和终止位置往两侧延伸5s(多丢10s)标记为要丢弃的segment
      - 第三阶段：ffmpeg工具裁掉要丢弃的segment，然后拼接视频（**目前存在问题，对于一个无人脸的转场segment不能随意拼接**）
      - 第四阶段：设定clip duration，对拼接的视频进行clip
   - **需要改进**
      - 设置两个阈值max/min clip duration
         - max duration：最大不超过这个阈值，超过触发保存视频
         - min duration：最小不低于这个阈值，低于丢弃视频片段
      - 逐帧检测视频（效率低可选择跳帧检测），遇到无人脸的部分进行片段长度判断舍弃还是保存（使用ffmpeg剪切）
#### 2.1.2 任务处理（针对任务需求）

- 目标
   - 对视频进行人脸检测并剪切得到人脸剪切数据集
   - 对声音进行提取，提取特征文件
- 方法
   - 检测人脸得到landmark，根据landmark检测人脸并进行crop
   - 根据需求，判断是否需要对人脸做对齐，crop后是否需要resize**（resize要谨慎选择，详解三种方式的插值）**
- 注意
   - 由于人脸的分辨率过高，直接检测可能显存消耗，**先将人脸进行resize**，再进行
#### 2.1.3 后处理（针对任务需求）

- 目标
   - 将处理得到的帧和音频特征进行处理符合Loader的方式
- 方法
   - **数据清洗（以DINet为例）**
      - **数据要求**
         - **将一个视频数据切为帧，按照9帧为一个片段存在按顺序命名的目录中（每个目录必须9帧）**
         - **1帧对应9帧的deepspeech特征，每个特征为29维度**
      - **操作**
         - **去掉不为9帧的目录**
         - **确保语音的长度特征对应的帧要大于或者等于crop face的帧数，因为是按照face读取数据的，去掉语音比帧数短的目录**
- **注意**
   - 由于帧数必须是9的倍数，对video进行clip的时候，可以尽量向9的倍数靠拢，减少丢掉的帧
   - 由于音频长度可能不取整，留下一个**毫秒级别的尾巴**（这个尾巴可能被算作一帧），这个时候需要将视频的尾巴去掉，不然会造成语音特征比帧数少的问题
## 2.2流程图

- 根据不同的任务需求
   - **convert_fps：**首先得到**25fps**的视频
   - **clean_video + clip：**对视频的每帧进行检测，检测不含人脸的帧，以及多人脸的帧，然后将较长的视频进行分段处理
   - **crop：**分段后根据任务需求进行crop提取音频等操作

![](https://cdn.nlark.com/yuque/0/2024/jpeg/34805283/1709993421417-1e14d8b9-8f23-4613-9479-bddcdcdbc796.jpeg)